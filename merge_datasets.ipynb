{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"twitter_data\"\n",
    "expected_columns = ['tweetid', 'userid', 'user_display_name', 'user_screen_name',\n",
    "       'user_reported_location', 'user_profile_description',\n",
    "       'user_profile_url', 'follower_count', 'following_count',\n",
    "       'account_creation_date', 'account_language', 'tweet_language',\n",
    "       'tweet_text', 'tweet_time', 'tweet_client_name', 'in_reply_to_userid',\n",
    "       'in_reply_to_tweetid', 'quoted_tweet_tweetid', 'is_retweet',\n",
    "       'retweet_userid', 'retweet_tweetid', 'latitude', 'longitude',\n",
    "       'quote_count', 'reply_count', 'like_count', 'retweet_count', 'hashtags',\n",
    "       'urls', 'user_mentions', 'poll_choices']\n",
    "dtypes = ['float64', 'str', 'str', 'str', 'str', 'str', 'str', 'float64', 'float64', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'str', 'float64', 'float64', 'float64', 'float64', 'str', 'str', 'str', 'str']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in tqdm(os.listdir(folder)):\n",
    "    # tqdm.write(\"File: \", file)\n",
    "    tqdm.write(\"File: {}\".format(file))\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(os.path.join(folder, file), dtype=dict(zip(expected_columns, dtypes)), parse_dates=[\"account_creation_date\", \"tweet_time\"], low_memory=False)\n",
    "    tqdm.write(\"Time to read: {}\".format(time.time() - start_time))\n",
    "    tqdm.write(\"Entries: {}\".format(df.shape[0]))\n",
    "    eng_tweets = df[df[\"tweet_language\"] == \"en\"]\n",
    "    tqdm.write(\"Number of english tweets: {} ({}%)\".format(eng_tweets.shape[0], eng_tweets.shape[0] / df.shape[0] * 100))\n",
    "    columns_diff_1 = set(df.columns.tolist()) - set(expected_columns)\n",
    "    columns_diff_2 = set(expected_columns) - set(df.columns.tolist())\n",
    "    tqdm.write(\"Columns match: {}\".format(len(columns_diff_1) == 0 and len(columns_diff_2) == 0))\n",
    "    if len(columns_diff_1) != 0:\n",
    "        tqdm.write(\"Extra columns: {}\".format(columns_diff_1))\n",
    "    if len(columns_diff_2) != 0:\n",
    "        tqdm.write(\"Missing columns: {}\".format(columns_diff_2))\n",
    "\n",
    "    # remove from memory\n",
    "    del df\n",
    "    tqdm.write(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot of these datasets are way to big to read into memory, so we need to read them in chunks\n",
    "# we only want to keep english tweets, so we can filter them out as we read them in\n",
    "# let's do this manually, without using pandas\n",
    "import csv\n",
    "\n",
    "folder = \"twitter_data\"\n",
    "output_file = \"english_tweets.csv\"\n",
    "\n",
    "for file in tqdm(os.listdir(folder)):\n",
    "    tqdm.write(\"File: {}\".format(file))\n",
    "    with open(os.path.join(folder, file), 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "\n",
    "        # find the index of the tweet language column\n",
    "        tweet_lang_idx = header.index(\"tweet_language\")\n",
    "\n",
    "        # iterate over the rows, and only write the english ones to the output file\n",
    "        with open(output_file, 'a') as out:\n",
    "            writer = csv.writer(out)\n",
    "            for row in reader:\n",
    "                if row[tweet_lang_idx] == \"en\":\n",
    "                    writer.writerow(row)\n",
    "    tqdm.write(\"Time to read: {}\".format(time.time() - start_time))\n",
    "    tqdm.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 19/27 [08:20<03:50, 28.87s/it]"
     ]
    }
   ],
   "source": [
    "# # combine all english, non-retweet tweets into a single dataframe\n",
    "# all_tweets = pd.DataFrame(columns=expected_columns)\n",
    "# initial_length = 0\n",
    "# for file in tqdm(os.listdir(folder)):\n",
    "#     # df = pd.read_csv(os.path.join(folder, file), low_memory=False)\n",
    "#     df = pd.read_csv(os.path.join(folder, file), dtype=dict(zip(expected_columns, dtypes)), low_memory=False) # parse_dates=[\"account_creation_date\", \"tweet_time\"], \n",
    "#     initial_length += df.shape[0]\n",
    "#     eng_tweets = df[df[\"tweet_language\"] == \"en\"]\n",
    "#     # non_retweets = eng_tweets[eng_tweets[\"is_retweet\"] == False]\n",
    "#     # all_tweets = pd.concat([all_tweets, non_retweets])\n",
    "#     all_tweets = pd.concat([all_tweets, eng_tweets])\n",
    "#     del df\n",
    "#     del eng_tweets\n",
    "#     # del non_retweets\n",
    "\n",
    "# print(\"Reduced from {} to {} entries\".format(initial_length, all_tweets.shape[0]))\n",
    "# all_tweets = all_tweets.drop(columns=[\"tweet_language\", \"is_retweet\"])\n",
    "# # save to csv\n",
    "# all_tweets.to_csv(\"all_tweets.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
